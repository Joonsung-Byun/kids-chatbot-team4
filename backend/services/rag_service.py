# services/rag_service.py
"""
RAG Service

- ë²¡í„° ê²€ìƒ‰
- í¬ë¡œìŠ¤ì¸ì½”ë” ë¦¬ëž­í‚¹
- MMR ë‹¤ì–‘ì„± í•„í„°ë§
"""
import os
from typing import List, Dict, Any, Optional

from utils.config import get_settings
from utils.logger import logger
from utils.vector_client import get_vector_client

class RAGService:
    """RAG ê¸°ë°˜ ë¬¸ì„œ/ì‹œì„¤ ê²€ìƒ‰ ì„œë¹„ìŠ¤"""

    def __init__(self) -> None:
        self.settings = get_settings()
        self.client = get_vector_client()
        self._cross_encoder = None
        self._use_gpu = self._detect_gpu()

        if self._use_gpu:
            self._load_reranker()

    def _detect_gpu(self) -> bool:
        """GPU í™˜ê²½ ê°ì§€"""
        try:
            import torch
            if torch.cuda.is_available():
                return True
        except ImportError:
            pass
        # Colab í™˜ê²½ ì²´í¬
        if "COLAB_RELEASE_TAG" in os.environ:
            return True
        return False

    def _load_reranker(self) -> None:
        """GPU í™˜ê²½ì—ì„œ CrossEncoder ëª¨ë¸ ë¡œë“œ"""
        try:
            from sentence_transformers import CrossEncoder
            model_name = self.settings.RERANKER_MODEL
            logger.info(f"ðŸ”„ í¬ë¡œìŠ¤ì¸ì½”ë” ë¡œë”©: {model_name}")
            self._cross_encoder = CrossEncoder(model_name, device="cuda")
            logger.info("âœ… í¬ë¡œìŠ¤ì¸ì½”ë” ë¡œë“œ ì™„ë£Œ")
        except Exception as e:
            logger.error(f"âŒ í¬ë¡œìŠ¤ì¸ì½”ë” ë¡œë“œ ì‹¤íŒ¨: {e}")
            self._cross_encoder = None

    def search_and_rerank(
        self,
        query: str,
        top_k: Optional[int] = None,
        filters: Optional[Dict[str, Any]] = None,
        use_multi_query: bool = True,
        use_mmr: bool = True,
    ) -> List[Dict[str, Any]]:
        """
        1) (ì„ íƒ) ë©€í‹°ì¿¼ë¦¬ í™•ìž¥
        2) ì´ˆê¸° ë²¡í„° ê²€ìƒ‰
        3) ì¤‘ë³µ ì œê±°
        4) (ì„ íƒ) í¬ë¡œìŠ¤ì¸ì½”ë” ë¦¬ëž­í‚¹
        5) (ì„ íƒ) MMR í•„í„°ë§
        """
        try:
            k = top_k or self.settings.MMR_TOP_K
            logger.info(f"ðŸ” RAG ê²€ìƒ‰ ì‹œìž‘: '{query}' (GPU={self._use_gpu})")

            # ë©€í‹°ì¿¼ë¦¬
            queries = [query]
            if use_multi_query and self._use_gpu:
                # TODO: LLM ê¸°ë°˜ ì¿¼ë¦¬ í™•ìž¥ êµ¬í˜„
                pass

            # ì´ˆê¸° ê²€ìƒ‰
            all_docs = []
            for q in queries:
                res = self.client.search(q, n_results=self.settings.TOP_K, where=filters)
                # res['documents'][0], res['metadatas'][0], res['distances'][0]
                formatted = self._format_results(res)
                all_docs.extend(formatted)

            # ì¤‘ë³µ ì œê±°
            unique_docs = self._dedupe(all_docs)

            # ë¦¬ëž­í‚¹
            if self._cross_encoder:
                reranked = self._rerank(query, unique_docs)
                if not reranked or len(reranked) == 0:
                    logger.warning("âš ï¸ ë¦¬ëž­í‚¹ ê²°ê³¼ê°€ ë¹„ì–´ ìžˆìŒ â†’ ì›ë³¸ ìƒìœ„ Nê°œ ìœ ì§€")
                    unique_docs = unique_docs[: self.settings.RERANK_TOP_K]
                else:
                    unique_docs = reranked
            else:
                logger.info("ðŸ’¡ GPU ë¹„í™œì„±í™” í™˜ê²½ â†’ ë¦¬ëž­í‚¹ ìƒëžµ, ìƒìœ„ Nê°œ ê·¸ëŒ€ë¡œ ì‚¬ìš©")
                unique_docs = unique_docs[: self.settings.RERANK_TOP_K]

            # MMR í•„í„°ë§ (í˜„ìž¬ëŠ” ìƒìœ„ Nê°œ ì¶”ì¶œ)
            final = unique_docs[:k] if use_mmr else unique_docs
            logger.info(f"âœ… RAG ê²€ìƒ‰ ì™„ë£Œ: {len(final)}ê°œ ë°˜í™˜")
            return final

        except Exception as e:
            logger.error(f"âŒ RAG ê²€ìƒ‰ ì˜¤ë¥˜: {e}")
            return []

    def _format_results(self, res: Dict[str, Any]) -> List[Dict[str, Any]]:
        """ChromaDB ê²°ê³¼ í¬ë§· ë³€í™˜ (ë¹ˆ ë¬¸ì„œ ì˜ˆì™¸ ì²˜ë¦¬)"""
        if not res or not res.get("documents") or not res["documents"][0]:
            return []

        docs = res.get("documents", [[]])[0]
        metas = res.get("metadatas", [[]])[0]
        dists = res.get("distances", [[]])[0]

        formatted = []
        for doc, meta, dist in zip(docs, metas, dists):
            if not doc or doc.strip() == "":
                continue
            formatted.append({
                "content": doc.strip(),
                "metadata": meta or {},
                "distance": dist,
                "similarity": round(1 - float(dist), 4)
            })

        return formatted

    def _dedupe(self, docs: List[Dict[str, Any]]) -> List[Dict[str, Any]]:
        """ì‹œì„¤ëª… ê¸°ì¤€ ì¤‘ë³µ ì œê±° (facility_name / Name ëŒ€ì‘)"""
        seen, unique = set(), []
        for d in docs:
            meta = d.get("metadata", {})
            name = meta.get("facility_name") or meta.get("Name")  # âœ… í•µì‹¬ ìˆ˜ì •
            if name and name not in seen:
                seen.add(name)
                unique.append(d)
        return unique
    
    def _rerank(self, query: str, docs: List[Dict[str, Any]]) -> List[Dict[str, Any]]:
        """í¬ë¡œìŠ¤ì¸ì½”ë”ë¡œ ë¦¬ëž­í‚¹"""
        try:
            pairs = [(query, d["content"]) for d in docs]
            scores = self._cross_encoder.predict(pairs)
            scored = []
            for doc, score in zip(docs, scores):
                if score >= self.settings.SIMILARITY_THRESHOLD:
                    doc["score"] = float(score)
                    scored.append(doc)
            scored.sort(key=lambda x: x["score"], reverse=True)
            return scored[: self.settings.RERANK_TOP_K]
        except Exception as e:
            logger.error(f"âŒ ë¦¬ëž­í‚¹ ì‹¤íŒ¨: {e}")
            return docs


# ì‹±ê¸€í†¤ ì¸ìŠ¤í„´ìŠ¤
_rag_service: RAGService = None


def get_rag_service() -> RAGService:
    """RAGService ì‹±ê¸€í†¤ ë°˜í™˜"""
    global _rag_service
    if _rag_service is None:
        _rag_service = RAGService()
    return _rag_service