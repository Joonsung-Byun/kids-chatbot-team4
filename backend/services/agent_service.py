# services/agent_service.py
"""
LangGraph Agent Service

LangGraphë¥¼ ì‚¬ìš©í•œ ë©€í‹°í„´ ëŒ€í™” ê´€ë¦¬
- Supervisor: ë£°ë² ì´ìŠ¤ë¡œ ë„êµ¬ ì„ íƒ
- Tools: Weather, RAG, Map
- Answer Generation: Qwen2.5-7B-Instruct
"""

from typing import Literal
from langgraph.graph import StateGraph, END

from models.chat_schema import ChatState
from services.supervisor_service import get_supervisor_service
from services.llm_service import get_llm_service
from services.rag_service import get_rag_service
from services.weather_service import get_weather
from services.map_service import get_map_markers
from utils.logger import logger


# ============================================================
# LangGraph Nodes
# ============================================================

def supervisor_node(state: ChatState) -> ChatState:
    """
    Supervisor Node: ì¿¼ë¦¬ ë¶„ì„ ë° ë„êµ¬ ì„ íƒ
    
    ë£°ë² ì´ìŠ¤ë¡œ ë‹¤ìŒì„ ìˆ˜í–‰:
    - ìœ„ì¹˜ ì¶”ì¶œ
    - ë‚ ì§œ ì¶”ì¶œ
    - í•„ìš”í•œ ë„êµ¬ ì„ íƒ (weather, rag, map)
    - ìœ„ì¹˜ ì—†ìœ¼ë©´ needs_location=True
    """
    logger.info(f"[Supervisor] ë¶„ì„ ì‹œì‘: '{state['user_query']}'")
    
    # ì´ì „ ëŒ€í™”ì—ì„œ ìœ„ì¹˜ ì •ë³´ ê°€ì ¸ì˜¤ê¸°
    current_location = state.get("location")
    
    # ëŒ€í™” ì»¨í…ìŠ¤íŠ¸ (ìµœê·¼ 5ê°œ ë©”ì‹œì§€)
    conversation_context = state["messages"][-5:] if state["messages"] else []
    
    # Supervisor ë¶„ì„
    supervisor = get_supervisor_service()
    result = supervisor.analyze_query(
        user_query=state["user_query"],
        conversation_context=conversation_context,
        current_location=current_location
    )
    
    # ìƒíƒœ ì—…ë°ì´íŠ¸
    state["location"] = result.get("location")
    state["date"] = result.get("date")
    state["selected_tools"] = result.get("selected_tools", [])
    state["needs_location"] = result.get("needs_location", False)
    
    logger.info(f"[Supervisor] ê²°ê³¼: location={state['location']}, tools={state['selected_tools']}, needs_location={state['needs_location']}")
    
    return state


def check_location_node(state: ChatState) -> ChatState:
    """
    ìœ„ì¹˜ í™•ì¸ Node
    
    ìœ„ì¹˜ê°€ í•„ìš”í•œë° ì—†ìœ¼ë©´ ì—­ì§ˆë¬¸ ìƒì„±
    """
    if state["needs_location"]:
        state["final_answer"] = "ì–´ëŠ ì§€ì—­ì„ ìƒê°í•˜ê³  ê³„ì‹ ê°€ìš”? ğŸ—ºï¸"
        logger.info("[CheckLocation] ìœ„ì¹˜ ì§ˆë¬¸ ìƒì„±")
    
    return state


def weather_tool_node(state: ChatState) -> ChatState:
    """
    Weather Tool Node
    
    ë‚ ì”¨ API í˜¸ì¶œ (ì„ íƒëœ ê²½ìš°ì—ë§Œ)
    """
    if "weather" not in state["selected_tools"]:
        return state
    
    try:
        logger.info(f"[WeatherTool] ë‚ ì”¨ ì¡°íšŒ: {state['location']}")
        
        weather_info = get_weather(
            location=state["location"],
            target_date=state.get("date")
        )
        
        state["weather_results"] = weather_info
        logger.info(f"[WeatherTool] ê²°ê³¼: {weather_info}")
        
    except Exception as e:
        logger.error(f"[WeatherTool] ì˜¤ë¥˜: {e}")
        state["weather_results"] = None
    
    return state


def rag_tool_node(state: ChatState) -> ChatState:
    """
    RAG Tool Node
    
    ë²¡í„° ê²€ìƒ‰ìœ¼ë¡œ ì‹œì„¤ ì°¾ê¸°
    """
    if "rag" not in state["selected_tools"]:
        return state
    
    try:
        logger.info(f"[RAGTool] ê²€ìƒ‰: {state['user_query']}")
        
        # ë©”íƒ€ë°ì´í„° í•„í„° êµ¬ì„±
        filters = {}
        if state.get("location"):
            # ìœ„ì¹˜ ê¸°ë°˜ í•„í„°ë§ (í•„ìš”ì‹œ ì¶”ê°€)
            pass
        
        # RAG ê²€ìƒ‰
        rag_service = get_rag_service()
        results = rag_service.search_and_rerank(
            query=state["user_query"],
            top_k=5,
            filters=filters or None
        )
        
        state["rag_results"] = results
        logger.info(f"[RAGTool] ê²°ê³¼: {len(results)}ê°œ ì‹œì„¤")
        
    except Exception as e:
        logger.error(f"[RAGTool] ì˜¤ë¥˜: {e}")
        state["rag_results"] = []
    
    return state


def map_tool_node(state: ChatState) -> ChatState:
    """
    Map Tool Node
    
    ì¹´ì¹´ì˜¤ë§µ ë°ì´í„° ìƒì„± (RAG ê²°ê³¼ ê¸°ë°˜)
    """
    if "map" not in state["selected_tools"]:
        return state
    
    try:
        # RAG ê²°ê³¼ì—ì„œ ì¢Œí‘œ ì¶”ì¶œ
        facilities = state.get("rag_results", [])
        
        if not facilities:
            logger.warning("[MapTool] RAG ê²°ê³¼ ì—†ìŒ - ì§€ë„ ìƒì„± ìŠ¤í‚µ")
            return state
        
        logger.info(f"[MapTool] ì§€ë„ ìƒì„±: {len(facilities)}ê°œ ì‹œì„¤")
        
        # TODO: ì‹¤ì œ ì¹´ì¹´ì˜¤ë§µ API ì—°ë™ ì‹œ ì‚¬ìš©
        # map_data = get_map_markers(state["user_query"])
        # state["map_results"] = map_data
        
        # ì„ì‹œ: RAG ê²°ê³¼ë¥¼ ì§€ë„ í˜•ì‹ìœ¼ë¡œ ë³€í™˜
        state["map_results"] = {
            "center": {"lat": 37.5665, "lng": 126.9780},  # ì„œìš¸ ê¸°ë³¸
            "markers": [
                {
                    "name": f["metadata"].get("facility_name", "Unknown"),
                    "lat": 37.5665 + i * 0.01,  # Mock ì¢Œí‘œ
                    "lng": 126.9780 + i * 0.01
                }
                for i, f in enumerate(facilities[:5])
            ]
        }
        
    except Exception as e:
        logger.error(f"[MapTool] ì˜¤ë¥˜: {e}")
        state["map_results"] = None
    
    return state


def generate_answer_node(state: ChatState) -> ChatState:
    """
    Answer Generation Node
    
    Qwen2.5-7B-Instructë¡œ ìµœì¢… ë‹µë³€ ìƒì„±
    """
    # 1. ìœ„ì¹˜ ì§ˆë¬¸ì´ ì´ë¯¸ ìƒì„±ëœ ê²½ìš°
    if state.get("final_answer"):
        logger.info("[GenerateAnswer] ìœ„ì¹˜ ì§ˆë¬¸ ì‚¬ìš©")
        return state
    
    # 2. ë„êµ¬ ì—†ìŒ (ì¼ë°˜ ëŒ€í™”)
    if not state["selected_tools"]:
        logger.info("[GenerateAnswer] ì¼ë°˜ ëŒ€í™” ì‘ë‹µ")
        llm_service = get_llm_service()
        
        # ê°„ë‹¨í•œ Mock ì‘ë‹µ (GPU í™˜ê²½ì—ì„œëŠ” ì‹¤ì œ LLM ì‚¬ìš©)
        state["final_answer"] = llm_service._mock_answer(
            state["user_query"],
            []
        )
        return state
    
    # 3. Tool ê²°ê³¼ ê¸°ë°˜ ì‘ë‹µ ìƒì„±
    try:
        logger.info("[GenerateAnswer] Tool ê²°ê³¼ ê¸°ë°˜ ì‘ë‹µ ìƒì„±")
        
        llm_service = get_llm_service()
        rag_results = state.get("rag_results", [])
        
        # ì»¨í…ìŠ¤íŠ¸ ë¬¸ì„œ í¬ë§· ë³€í™˜
        context_docs = []
        for doc in rag_results:
            context_docs.append({
                "content": doc.get("content", ""),
                "metadata": doc.get("metadata", {})
            })
        
        # LLM ë‹µë³€ ìƒì„±
        answer = llm_service.generate_answer(
            query=state["user_query"],
            context_docs=context_docs
        )
        
        # ë‚ ì”¨ ì •ë³´ ì¶”ê°€ (ìˆìœ¼ë©´)
        if state.get("weather_results"):
            weather = state["weather_results"]
            answer = f"ğŸŒ¤ï¸ ë‚ ì”¨: {weather}\n\n{answer}"
        
        state["final_answer"] = answer
        logger.info(f"[GenerateAnswer] ì™„ë£Œ: {len(answer)}ì")
        
    except Exception as e:
        logger.error(f"[GenerateAnswer] ì˜¤ë¥˜: {e}")
        state["final_answer"] = "ì£„ì†¡í•©ë‹ˆë‹¤. ì‘ë‹µ ìƒì„± ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤."
    
    return state


# ============================================================
# Routing Functions
# ============================================================

def should_ask_location(state: ChatState) -> Literal["ask_location", "execute_tools"]:
    """
    ì¡°ê±´ë¶€ ë¼ìš°íŒ…: ìœ„ì¹˜ ì§ˆë¬¸ vs ë„êµ¬ ì‹¤í–‰
    """
    if state["needs_location"]:
        return "ask_location"
    return "execute_tools"


def should_run_weather(state: ChatState) -> Literal["weather", "rag"]:
    """
    ì¡°ê±´ë¶€ ë¼ìš°íŒ…: ë‚ ì”¨ ë„êµ¬ ì‹¤í–‰ ì—¬ë¶€
    """
    if "weather" in state["selected_tools"]:
        return "weather"
    return "rag"


def should_run_rag(state: ChatState) -> Literal["rag", "map"]:
    """
    ì¡°ê±´ë¶€ ë¼ìš°íŒ…: RAG ë„êµ¬ ì‹¤í–‰ ì—¬ë¶€
    """
    if "rag" in state["selected_tools"]:
        return "rag"
    return "map"


def should_run_map(state: ChatState) -> Literal["map", "generate"]:
    """
    ì¡°ê±´ë¶€ ë¼ìš°íŒ…: Map ë„êµ¬ ì‹¤í–‰ ì—¬ë¶€
    """
    if "map" in state["selected_tools"]:
        return "map"
    return "generate"


# ============================================================
# Graph Creation
# ============================================================

def create_agent_graph():
    """
    LangGraph Agent ìƒì„±
    
    ì›Œí¬í”Œë¡œìš°:
    START â†’ Supervisor â†’ [ìœ„ì¹˜ ì§ˆë¬¸ OR ë„êµ¬ ì‹¤í–‰] â†’ ë‹µë³€ ìƒì„± â†’ END
    """
    logger.info("ğŸ”§ LangGraph Agent ìƒì„± ì¤‘...")
    
    workflow = StateGraph(ChatState)
    
    # Nodes ì¶”ê°€
    workflow.add_node("supervisor", supervisor_node)
    workflow.add_node("check_location", check_location_node)
    workflow.add_node("weather_tool", weather_tool_node)
    workflow.add_node("rag_tool", rag_tool_node)
    workflow.add_node("map_tool", map_tool_node)
    workflow.add_node("generate_answer", generate_answer_node)
    
    # Entry point
    workflow.set_entry_point("supervisor")
    
    # ì¡°ê±´ë¶€ ë¼ìš°íŒ…: Supervisor â†’ ìœ„ì¹˜ ì§ˆë¬¸ OR ë„êµ¬ ì‹¤í–‰
    workflow.add_conditional_edges(
        "supervisor",
        should_ask_location,
        {
            "ask_location": "check_location",
            "execute_tools": "weather_tool"
        }
    )
    
    # ìœ„ì¹˜ ì§ˆë¬¸ â†’ ì¢…ë£Œ
    workflow.add_edge("check_location", END)
    
    # ë„êµ¬ ì‹¤í–‰ ì²´ì¸ (ì¡°ê±´ë¶€)
    workflow.add_conditional_edges(
        "weather_tool",
        should_run_rag,
        {
            "rag": "rag_tool",
            "map": "map_tool"
        }
    )
    
    workflow.add_conditional_edges(
        "rag_tool",
        should_run_map,
        {
            "map": "map_tool",
            "generate": "generate_answer"
        }
    )
    
    workflow.add_edge("map_tool", "generate_answer")
    workflow.add_edge("generate_answer", END)
    
    logger.info("âœ… LangGraph Agent ìƒì„± ì™„ë£Œ")
    
    return workflow.compile()


# ============================================================
# Main Chat Function
# ============================================================

def run_agent(
    user_query: str,
    conversation_id: str,
    conversation_history: list = None
) -> dict:
    """
    Agent ì‹¤í–‰
    
    Args:
        user_query: ì‚¬ìš©ì ì…ë ¥
        conversation_id: ëŒ€í™” ì„¸ì…˜ ID
        conversation_history: ì´ì „ ëŒ€í™” íˆìŠ¤í† ë¦¬
    
    Returns:
        {
            "answer": str,
            "conversation_history": list,
            "location": str,
            "tools_used": list
        }
    """
    logger.info(f"ğŸš€ Agent ì‹¤í–‰: conversation_id={conversation_id}")
    
    # Graph ìƒì„±
    graph = create_agent_graph()
    
    # ì´ˆê¸° ìƒíƒœ
    initial_state = ChatState(
        messages=conversation_history or [],
        conversation_id=conversation_id,
        user_query=user_query,
        location=None,
        date=None,
        selected_tools=[],
        needs_location=False,
        weather_results=None,
        rag_results=None,
        map_results=None,
        final_answer=""
    )
    
    # ì´ì „ íˆìŠ¤í† ë¦¬ì—ì„œ ìœ„ì¹˜ ì¶”ì¶œ ì‹œë„
    if conversation_history:
        supervisor = get_supervisor_service()
        for msg in reversed(conversation_history):
            if msg["role"] == "user":
                location = supervisor._extract_location(msg["content"])
                if location:
                    initial_state["location"] = location
                    logger.info(f"[Agent] íˆìŠ¤í† ë¦¬ì—ì„œ ìœ„ì¹˜ ì¶”ì¶œ: {location}")
                    break
    
    # ì‚¬ìš©ì ë©”ì‹œì§€ ì¶”ê°€
    initial_state["messages"].append({"role": "user", "content": user_query})
    
    # Graph ì‹¤í–‰
    result = graph.invoke(initial_state)
    
    # AI ì‘ë‹µ ì¶”ê°€
    if result["final_answer"]:
        result["messages"].append({"role": "ai", "content": result["final_answer"]})
    
    logger.info(f"âœ… Agent ì™„ë£Œ: tools={result['selected_tools']}")
    
    return {
        "answer": result["final_answer"],
        "conversation_history": result["messages"],
        "location": result.get("location"),
        "tools_used": result["selected_tools"],
        "map_data": result.get("map_results")
    }
    
    
    