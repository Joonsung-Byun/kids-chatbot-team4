"""
ChromaDB ë°ì´í„° ì´ˆê¸°í™” ìŠ¤í¬ë¦½íŠ¸ (ì•ˆì „í˜•)
----------------------------------------
CSVì˜ ì»¬ëŸ¼ ê²°ì¸¡ì¹˜ë¥¼ ìë™ ì²˜ë¦¬í•˜ê³ ,
ì‹œì„¤ ì •ë³´ë¥¼ ìì—°ì–´ descriptionìœ¼ë¡œ ë³€í™˜í•´ ChromaDBì— ì—…ë¡œë“œí•©ë‹ˆë‹¤.
"""

import sys
import os
import pandas as pd
from pathlib import Path

# backend ê²½ë¡œ ì¸ì‹
sys.path.insert(0, str(Path(__file__).parent.parent))

from utils.vector_client import get_vector_client
from utils.logger import logger


def safe_get(row, key):
    """ê²°ì¸¡ê°’ì´ë‚˜ Noneì„ ì•ˆì „í•˜ê²Œ ê°€ì ¸ì˜¤ê¸°"""
    val = row.get(key, "")
    if pd.isna(val) or str(val).strip() in ["", "nan", "None"]:
        return ""
    return str(val).strip()


def build_description(row: pd.Series) -> str:
    """CSV í•œ í–‰(row)ì—ì„œ ìì—°ì–´ descriptionì„ ìƒì„±"""
    parts = []

    name = safe_get(row, "Name")
    region = " ".join(filter(None, [safe_get(row, "CTPRVN_NM"), safe_get(row, "SIGNGU_NM")]))
    category = " ".join(
        filter(None, [safe_get(row, "Category1"), safe_get(row, "Category2"), safe_get(row, "Category3")])
    )

    if name:
        parts.append(f"{name}ì€(ëŠ”)")
    if region:
        parts.append(f"{region}ì— ìœ„ì¹˜í•œ")
    if category:
        parts.append(f"{category} ê´€ë ¨ ì‹œì„¤ì…ë‹ˆë‹¤.")
    else:
        parts.append("ê°€ì¡± ë° ìœ ì•„ê°€ í•¨ê»˜ ì¦ê¸¸ ìˆ˜ ìˆëŠ” ì‹œì„¤ì…ë‹ˆë‹¤.")

    # ì¶”ê°€ ì •ë³´
    inout = safe_get(row, "in_out")
    cost = safe_get(row, "Cost")
    age = safe_get(row, "Age")
    time = safe_get(row, "Time")
    day = safe_get(row, "Day")
    note = safe_get(row, "Note")
    address = safe_get(row, "Address")

    if inout:
        parts.append(f"ì´ ì‹œì„¤ì€ {inout} ì¥ì†Œì´ë©°,")
    if age:
        parts.append(f"ì´ìš© ì—°ë ¹ëŒ€ëŠ” {age}ì…ë‹ˆë‹¤.")
    if cost:
        parts.append(f"ì´ìš© ìš”ê¸ˆì€ {cost}ì…ë‹ˆë‹¤.")
    if time or day:
        parts.append(f"ìš´ì˜ ì‹œê°„ì€ {day} {time}ì…ë‹ˆë‹¤.")
    if address:
        parts.append(f"ì£¼ì†ŒëŠ” {address}ì…ë‹ˆë‹¤.")
    if note:
        parts.append(note)

    # ë¬¸ì¥ ê²°í•© + ì¤‘ë³µ ì¡°ì‚¬ ì œê±°
    text = " ".join(filter(None, parts))
    text = text.replace("  ", " ").strip()

    return text


def load_csv_to_chroma(csv_path: str, batch_size: int = 100):
    """CSV íŒŒì¼ì„ ChromaDBì— ë¡œë“œ"""
    try:
        logger.info(f"ğŸ“‚ CSV íŒŒì¼ ë¡œë”©: {csv_path}")
        df = pd.read_csv(csv_path)
        logger.info(f"âœ… {len(df)}ê°œ í–‰ ë¡œë“œ ì™„ë£Œ")

        # description ìƒì„±
        logger.info("ğŸ§© description ì»¬ëŸ¼ ìë™ ìƒì„± ì¤‘...")
        df["description"] = df.apply(build_description, axis=1)

        # Nameê³¼ descriptionì´ ë¹„ì–´ ìˆëŠ” í–‰ ì œê±°
        df = df.dropna(subset=["Name", "description"])
        df = df[df["description"].str.strip() != ""]
        logger.info(f"ğŸ§¹ ì •ì œ í›„ {len(df)}ê°œ í–‰ ë‚¨ìŒ")

        # VectorClient ì´ˆê¸°í™”
        client = get_vector_client()
        total_batches = (len(df) + batch_size - 1) // batch_size
        logger.info(f"ğŸ“¦ ì´ {total_batches}ê°œ ë°°ì¹˜ ì—…ë¡œë“œ ì˜ˆì •")

        for i in range(0, len(df), batch_size):
            batch_df = df.iloc[i:i+batch_size]
            batch_num = (i // batch_size) + 1
            
            logger.info(f"â³ ë°°ì¹˜ {batch_num}/{total_batches} ì²˜ë¦¬ ì¤‘...")

            # NaN â†’ None (JSON ì§ë ¬í™” ê°€ëŠ¥í•˜ë„ë¡)
            batch_df = batch_df.where(pd.notnull(batch_df), None)

            # ë¬¸ì„œ ë° ë©”íƒ€ë°ì´í„° ì¤€ë¹„
            documents = batch_df["description"].fillna("").astype(str).tolist()
            metadatas = batch_df.astype(str).to_dict("records")
            ids = [f"facility_{idx}" for idx in batch_df.index]

            client.add_documents(
                documents=documents,
                metadatas=metadatas,
                ids=ids
            )
            
            logger.info(f"âœ… ë°°ì¹˜ {batch_num} ì™„ë£Œ ({len(documents)}ê°œ ë¬¸ì„œ)")

        logger.info("ğŸ‰ ë°ì´í„° ë¡œë“œ ì™„ë£Œ!")
        info = client.get_collection_info()
        logger.info(f"ğŸ“Š ì´ ë¬¸ì„œ ìˆ˜: {info['count']}")
        logger.info(f"ğŸ“š ì»¬ë ‰ì…˜ ì´ë¦„: {info['name']}")
        return True

    except Exception as e:
        logger.error(f"âŒ ë°ì´í„° ë¡œë“œ ì‹¤íŒ¨: {e}")
        import traceback
        traceback.print_exc()
        return False


def main():
    import argparse

    parser = argparse.ArgumentParser(description="CSV ë°ì´í„°ë¥¼ ChromaDBì— ë¡œë“œ")
    parser.add_argument("csv_path", type=str, help="CSV íŒŒì¼ ê²½ë¡œ")
    parser.add_argument("--batch-size", type=int, default=100, help="ë°°ì¹˜ í¬ê¸° (ê¸°ë³¸ê°’: 100)")
    args = parser.parse_args()

    success = load_csv_to_chroma(args.csv_path, args.batch_size)
    if not success:
        sys.exit(1)

    logger.info("ğŸ‰ ëª¨ë“  ì‘ì—… ì™„ë£Œ!")


if __name__ == "__main__":
    main()