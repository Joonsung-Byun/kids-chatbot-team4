"""
ChromaDB Vector Client (ë¡œì»¬ ì„œë²„ ì§€ì›)

ChromaDB Cloud â†’ ë¡œì»¬ ChromaDB ì„œë²„ë¡œ ì „í™˜
Docker Compose í™˜ê²½ì—ì„œ chromadb ì„œë¹„ìŠ¤ì™€ ì—°ê²°
"""

import os
import hashlib
from typing import List, Dict, Any, Optional

import chromadb
import numpy as np

from utils.config import get_settings
from utils.logger import logger


class VectorClient:
    """ChromaDB í´ë¼ì´ì–¸íŠ¸ (ë¡œì»¬/í´ë¼ìš°ë“œ ìë™ ê°ì§€)"""
    
    def __init__(self):
        self.settings = get_settings()
        self.client = None
        self.collection = None
        self._embedding_model = None
        self._is_gpu_environment = self._detect_environment()
        
        # ChromaDB ì—°ê²° (ë¡œì»¬ ìš°ì„ )
        self._connect()
        
        # GPU í™˜ê²½ì´ë©´ ì„ë² ë”© ëª¨ë¸ ë¡œë“œ
        if self._is_gpu_environment:
            self._load_embedding_model()
    
    def _detect_environment(self) -> bool:
        """GPU í™˜ê²½ ê°ì§€"""
        # í™˜ê²½ë³€ìˆ˜ë¡œ ëª…ì‹œì  ì„¤ì •
        use_gpu = os.getenv("USE_GPU", "false").lower() == "true"
        if use_gpu:
            logger.info("ğŸ” USE_GPU=true í™˜ê²½ë³€ìˆ˜ ê°ì§€")
            return True
        
        # Colab í™˜ê²½
        if "COLAB_RELEASE_TAG" in os.environ:
            logger.info("ğŸ” ì½”ë© í™˜ê²½ ê°ì§€ë¨")
            return True
        
        # CUDA ì‚¬ìš© ê°€ëŠ¥ ì—¬ë¶€
        try:
            import torch
            if torch.cuda.is_available():
                logger.info("ğŸ” GPU í™˜ê²½ ê°ì§€ë¨")
                return True
        except ImportError:
            logger.info("ğŸ” torch ë¯¸ì„¤ì¹˜ - ë¡œì»¬ CPU í™˜ê²½ìœ¼ë¡œ íŒë‹¨")
        
        logger.info("ğŸ” CPU í™˜å¢ƒ ê°ì§€ë¨ (Mock ì„ë² ë”© ì‚¬ìš©)")
        return False
    
    def _connect(self):
        """ChromaDB ì—°ê²° (ë¡œì»¬ ì„œë²„ ìš°ì„ , fallback to Cloud)"""
        try:
            # 1. ë¡œì»¬ ChromaDB ì„œë²„ ì‹œë„ (Docker Compose)
            chroma_host = os.getenv("CHROMA_HOST", "localhost")
            chroma_port = int(os.getenv("CHROMA_PORT", "8000"))
            
            if chroma_host != "localhost" or os.getenv("ENVIRONMENT") == "docker":
                logger.info(f"ğŸ”— ë¡œì»¬ ChromaDB ì„œë²„ ì—°ê²° ì‹œë„: {chroma_host}:{chroma_port}")
                
                self.client = chromadb.HttpClient(
                    host=chroma_host,
                    port=chroma_port
                )
                
                # ì»¬ë ‰ì…˜ ê°€ì ¸ì˜¤ê¸° ë˜ëŠ” ìƒì„±
                try:
                    self.collection = self.client.get_collection(
                        name=self.settings.CHROMA_COLLECTION_NAME
                    )
                    logger.info(f"âœ… ê¸°ì¡´ ì»¬ë ‰ì…˜ ë¡œë“œ: {self.collection.name}")
                except Exception:
                    logger.info(f"ğŸ“¦ ìƒˆ ì»¬ë ‰ì…˜ ìƒì„±: {self.settings.CHROMA_COLLECTION_NAME}")
                    self.collection = self.client.create_collection(
                        name=self.settings.CHROMA_COLLECTION_NAME,
                        metadata={"description": "Kids activity facilities"}
                    )
                
                logger.info(f"âœ… ë¡œì»¬ ChromaDB ì—°ê²° ì„±ê³µ: {self.collection.count()}ê°œ ë¬¸ì„œ")
                return
            
        except Exception as e:
            logger.warning(f"âš ï¸ ë¡œì»¬ ChromaDB ì—°ê²° ì‹¤íŒ¨: {e}")
        
        # 2. ChromaDB Cloud ì‹œë„ (fallback)
        try:
            if self.settings.CHROMA_API_KEY and self.settings.CHROMA_TENANT:
                logger.info("ğŸ”— ChromaDB Cloud ì—°ê²° ì‹œë„...")
                
                self.client = chromadb.CloudClient(
                    api_key=self.settings.CHROMA_API_KEY,
                    tenant=self.settings.CHROMA_TENANT,
                    database=self.settings.CHROMA_DATABASE,
                )
                
                self.collection = self.client.get_collection(
                    name=self.settings.CHROMA_COLLECTION_NAME
                )
                
                logger.info(f"âœ… ChromaDB Cloud ì—°ê²° ì„±ê³µ: {self.collection.count()}ê°œ ë¬¸ì„œ")
                return
        
        except Exception as e:
            logger.error(f"âŒ ChromaDB Cloud ì—°ê²° ì‹¤íŒ¨: {e}")
        
        # 3. ëª¨ë“  ì—°ê²° ì‹¤íŒ¨ ì‹œ ì—ëŸ¬
        raise ConnectionError("ChromaDB ì—°ê²° ì‹¤íŒ¨: ë¡œì»¬ ì„œë²„ì™€ Cloud ëª¨ë‘ ì—°ê²°í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
    
    def _load_embedding_model(self):
        """ì„ë² ë”© ëª¨ë¸ ë¡œë“œ (GPU í™˜ê²½)"""
        try:
            from sentence_transformers import SentenceTransformer
            
            logger.info(f"ğŸ”„ ì„ë² ë”© ëª¨ë¸ ë¡œë”© ì¤‘: {self.settings.EMBEDDING_MODEL}")
            
            self._embedding_model = SentenceTransformer(
                self.settings.EMBEDDING_MODEL,
                device='cuda' if self._is_gpu_environment else 'cpu'
            )
            
            logger.info("âœ… ì„ë² ë”© ëª¨ë¸ ë¡œë“œ ì™„ë£Œ")
            
        except Exception as e:
            logger.error(f"âŒ ì„ë² ë”© ëª¨ë¸ ë¡œë“œ ì‹¤íŒ¨: {e}")
            logger.warning("Mock ì„ë² ë”©ìœ¼ë¡œ ëŒ€ì²´í•©ë‹ˆë‹¤")
            self._is_gpu_environment = False
            self._embedding_model = None
    
    def search(
        self,
        query_text: str,
        n_results: int = 10,
        where: Optional[Dict[str, Any]] = None,
        where_document: Optional[Dict[str, Any]] = None
    ) -> Dict[str, Any]:
        """ë²¡í„° ê²€ìƒ‰"""
        try:
            env_status = "GPU" if self._is_gpu_environment else "Mock"
            logger.info(f"ğŸ” ê²€ìƒ‰ ì¿¼ë¦¬: '{query_text}' (n_results={n_results}, í™˜ê²½={env_status})")
            
            if where:
                logger.info(f"   ë©”íƒ€ë°ì´í„° í•„í„°: {where}")
            
            # ì¿¼ë¦¬ ì„ë² ë”©
            query_embedding = self._encode_query(query_text)
            
            # ChromaDB ê²€ìƒ‰
            results = self.collection.query(
                query_embeddings=[query_embedding],
                n_results=n_results,
                where=where,
                where_document=where_document,
                include=["documents", "metadatas", "distances"]
            )
            
            logger.info(f"âœ… ê²€ìƒ‰ ì™„ë£Œ: {len(results['ids'][0])}ê°œ ê²°ê³¼")
            
            if results['distances'][0]:
                top_distances = results['distances'][0][:3]
                logger.info(f"   ìƒìœ„ 3ê°œ ê±°ë¦¬: {[f'{d:.4f}' for d in top_distances]}")
            
            return results
            
        except Exception as e:
            logger.error(f"âŒ ê²€ìƒ‰ ì‹¤íŒ¨: {e}")
            raise
    
    def _encode_query(self, query_text: str) -> List[float]:
        """ì¿¼ë¦¬ í…ìŠ¤íŠ¸ ì„ë² ë”©"""
        try:
            if self._is_gpu_environment and self._embedding_model is not None:
                return self._encode_with_real_model(query_text)
            else:
                return self._encode_with_mock(query_text)
                
        except Exception as e:
            logger.error(f"âŒ ì„ë² ë”© ìƒì„± ì‹¤íŒ¨: {e}")
            logger.warning("Mock ì„ë² ë”©ìœ¼ë¡œ ëŒ€ì²´")
            return self._encode_with_mock(query_text)
    
    def _encode_with_real_model(self, query_text: str) -> List[float]:
        """ì‹¤ì œ ëª¨ë¸ë¡œ ì„ë² ë”© ìƒì„±"""
        try:
            embeddings = self._embedding_model.encode([query_text])
            embedding_vector = embeddings[0].tolist()
            
            logger.debug(f"âœ… ì‹¤ì œ ëª¨ë¸ ì„ë² ë”© ìƒì„±: {len(embedding_vector)}ì°¨ì›")
            return embedding_vector
            
        except Exception as e:
            logger.error(f"ì‹¤ì œ ëª¨ë¸ ì„ë² ë”© ì‹¤íŒ¨: {e}")
            raise
    
    def _encode_with_mock(self, query_text: str) -> List[float]:
        """Mock ì„ë² ë”© ìƒì„± (ê°œë°œìš©)"""
        try:
            hash_obj = hashlib.md5(query_text.encode('utf-8'))
            seed = int(hash_obj.hexdigest(), 16) % (2**32)
            
            np.random.seed(seed)
            fake_embedding = np.random.normal(0, 1, 3584)
            
            norm = np.linalg.norm(fake_embedding)
            if norm > 0:
                fake_embedding = fake_embedding / norm
            
            logger.debug(f"ğŸ”„ Mock ì„ë² ë”© ìƒì„±: '{query_text[:30]}...' -> 3584ì°¨ì›")
            return fake_embedding.tolist()
            
        except Exception as e:
            logger.error(f"Mock ì„ë² ë”© ìƒì„± ì‹¤íŒ¨: {e}")
            return [0.0] * 3584
    
    def add_documents(
        self,
        documents: List[str],
        metadatas: List[Dict[str, Any]],
        ids: Optional[List[str]] = None
    ) -> None:
        """ë¬¸ì„œ ì¶”ê°€ (ì´ˆê¸° ë°ì´í„° ë¡œë”©ìš©)"""
        try:
            if ids is None:
                ids = [f"doc_{i}" for i in range(len(documents))]
            
            # ì„ë² ë”© ìƒì„±
            if self._is_gpu_environment and self._embedding_model:
                embeddings = self._embedding_model.encode(documents).tolist()
            else:
                embeddings = [self._encode_with_mock(doc) for doc in documents]
            
            # ChromaDBì— ì¶”ê°€
            self.collection.add(
                documents=documents,
                metadatas=metadatas,
                ids=ids,
                embeddings=embeddings
            )
            
            logger.info(f"âœ… {len(documents)}ê°œ ë¬¸ì„œ ì¶”ê°€ ì™„ë£Œ")
            
        except Exception as e:
            logger.error(f"âŒ ë¬¸ì„œ ì¶”ê°€ ì‹¤íŒ¨: {e}")
            raise
    
    def get_collection_info(self) -> Dict[str, Any]:
        """ì»¬ë ‰ì…˜ ì •ë³´ ë°˜í™˜"""
        try:
            return {
                "name": self.collection.name,
                "count": self.collection.count(),
                "metadata": self.collection.metadata,
                "environment": "GPU" if self._is_gpu_environment else "CPU (Mock)",
                "model_loaded": self._embedding_model is not None,
                "embedding_model": self.settings.EMBEDDING_MODEL,
                "connection_type": "Local Server" if os.getenv("CHROMA_HOST") else "Cloud"
            }
        except Exception as e:
            logger.error(f"ì»¬ë ‰ì…˜ ì •ë³´ ì¡°íšŒ ì‹¤íŒ¨: {e}")
            return {"error": str(e)}


# ì‹±ê¸€í†¤ ì¸ìŠ¤í„´ìŠ¤
_vector_client_instance = None


def get_vector_client() -> VectorClient:
    """VectorClient ì‹±ê¸€í†¤ ë°˜í™˜"""
    global _vector_client_instance
    
    if _vector_client_instance is None:
        logger.info("ğŸ”§ VectorClient ì¸ìŠ¤í„´ìŠ¤ ìƒì„± ì¤‘...")
        _vector_client_instance = VectorClient()
        
        info = _vector_client_instance.get_collection_info()
        logger.info(f"ğŸ“Š í™˜ê²½: {info.get('environment')}")
        logger.info(f"ğŸ“Š ì—°ê²°: {info.get('connection_type')}")
        logger.info(f"ğŸ“Š ëª¨ë¸: {info.get('embedding_model')}")
        logger.info(f"ğŸ“Š ì»¬ë ‰ì…˜: {info.get('name')} ({info.get('count')}ê°œ ë¬¸ì„œ)")
    
    return _vector_client_instance


def reset_vector_client():
    """VectorClient ì´ˆê¸°í™” (í…ŒìŠ¤íŠ¸ìš©)"""
    global _vector_client_instance
    _vector_client_instance = None
    logger.info("ğŸ”„ VectorClient ì¸ìŠ¤í„´ìŠ¤ê°€ ì´ˆê¸°í™”ë˜ì—ˆìŠµë‹ˆë‹¤")


if __name__ == "__main__":
    print("ğŸ§ª VectorClient í…ŒìŠ¤íŠ¸ ì‹œì‘")
    client = get_vector_client()
    info = client.get_collection_info()
    print(f"ì—°ê²° ì •ë³´: {info}")